{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS108 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    " - Chiehkun (Timo) Chen\n",
    " - Jordan Daley\n",
    " - Jacob Moul\n",
    " - Hannah Peterson\n",
    " - Yun (Denise) Tang\n",
    " - George Thomas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Member IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (Timo)\n",
    " - (Jordan)\n",
    " - A13548393\n",
    " - A13724073\n",
    " - (Denise)\n",
    " - (George)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: Did the 2011-19 drought in California disproportionately affect low-income communities?\n",
    "\n",
    "This project will examine the impacts of climate change on low-income communities (specifically through the climatic event of drought). We will focus on California, because it has experienced prolonged drought within the past decade (for 376 consecutive weeks—Dec 2011 - March 2019). In particular, we will investigate whether or not the California drought has had disproportionate negative effects on low-income communities compared to average and high-income communities. This question is important because as the effects of global warming become more severe, efforts must be made to protect communities that are most vulnerable to these negative effects.\n",
    "\n",
    "To answer this question we are planning on analyzing different indicators of economic well being and different effects of drought for various communities over time, from before during and after the most recent drought. For example, we plan to investigate the relationships between income in communities and costs associated with the drought, such as utility rates, as well as potential health issues, such as respiratory illnesses, that are known to increase in conjunction with drought."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work\n",
    "\n",
    "*Background research*\n",
    "\n",
    "References:\n",
    " - 1)\n",
    " - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis: The 2011-19 drought in California did disproportionately affect low-income communities.\n",
    "\n",
    "We expect to find that these communities will have suffered more than relatively better-off communities because they have fewer safeguards to deal with environmental events, and also have less means to bear the cost of higher utility or healthcare rates, for example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your dataset information here*\n",
    "\n",
    "(Copy this information for each dataset)\n",
    "\n",
    " - Dataset Name:\n",
    " - Link to the dataset:\n",
    " - Number of observations:\n",
    "\n",
    "1-2 sentences describing each dataset.\n",
    "\n",
    "If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Community Economic Data**\n",
    " - Data Set Name: 'cbp[yr]co.txt' (For years 2012-2016)\n",
    "      - We modified these files to include only observations for California, and they have been renamed 'cbp[yr]co_mod.csv'\n",
    " - Source: https://www.census.gov/programs-surveys/cbp/data/datasets.html\n",
    " - Number of observations: 36616\n",
    "\n",
    "> These data sets are County Business Pattern data sets, and are provided with the description: “This series includes the number of establishments, employment during the week of March 12, first quarter payroll, and annual payroll. This data is useful for studying the economic activity of small areas; analyzing economic changes over time; and as a benchmark for other statistical series, surveys, and databases between economic censuses”. After being condensed to just the state of California, the 2016 data set (out of many others) is composed of 36616 observations of 26 variables, several of which are identifying information such as state or county code. In addition, it contains values for first quarter payroll, annual payroll, and number of employees, among other variables, for different industries in each county of California. This data comes from the US Census Bureau. All of these data sets are downloadable in csv format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple data sets: community business patterns, drought data, and unemployment data. We plan to merge these data sets by county and year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import County Business Patterns Data, add year to each table\n",
    "\n",
    "cbp00 = pd.read_csv('Data/cb_patterns/cbp00co_mod.csv')\n",
    "cbp01 = pd.read_csv('Data/cb_patterns/cbp01co_mod.csv')\n",
    "cbp02 = pd.read_csv('Data/cb_patterns/cbp02co_mod.csv')\n",
    "cbp03 = pd.read_csv('Data/cb_patterns/cbp03co_mod.csv')\n",
    "cbp04 = pd.read_csv('Data/cb_patterns/cbp04co_mod.csv')\n",
    "cbp05 = pd.read_csv('Data/cb_patterns/cbp05co_mod.csv')\n",
    "cbp06 = pd.read_csv('Data/cb_patterns/cbp06co_mod.csv')\n",
    "cbp07 = pd.read_csv('Data/cb_patterns/cbp07co_mod.csv')\n",
    "cbp08 = pd.read_csv('Data/cb_patterns/cbp08co_mod.csv')\n",
    "cbp09 = pd.read_csv('Data/cb_patterns/cbp09co_mod.csv')\n",
    "cbp10 = pd.read_csv('Data/cb_patterns/cbp10co_mod.csv')\n",
    "cbp11 = pd.read_csv('Data/cb_patterns/cbp11co_mod.csv')\n",
    "cbp12 = pd.read_csv('Data/cb_patterns/cbp12co_mod.csv')\n",
    "cbp13 = pd.read_csv('Data/cb_patterns/cbp13co_mod.csv')\n",
    "cbp14 = pd.read_csv('Data/cb_patterns/cbp14co_mod.csv')\n",
    "cbp15 = pd.read_csv('Data/cb_patterns/cbp15co_mod.csv')\n",
    "cbp16 = pd.read_csv('Data/cb_patterns/cbp16co_mod.csv')\n",
    "\n",
    "cbp00['year'] = 2000\n",
    "cbp01['year'] = 2001\n",
    "cbp02['year'] = 2002\n",
    "cbp03['year'] = 2003\n",
    "cbp04['year'] = 2004\n",
    "cbp05['year'] = 2005\n",
    "cbp06['year'] = 2006\n",
    "cbp07['year'] = 2007\n",
    "cbp08['year'] = 2008\n",
    "cbp09['year'] = 2009\n",
    "cbp10['year'] = 2010\n",
    "cbp11['year'] = 2011\n",
    "cbp12['year'] = 2012\n",
    "cbp13['year'] = 2013\n",
    "cbp14['year'] = 2014\n",
    "cbp15['year'] = 2015\n",
    "cbp16['year'] = 2016\n",
    "\n",
    "cbp_data = [cbp00, cbp01, cbp02, cbp03, cbp04, cbp05, cbp06, cbp07, cbp08, \n",
    "            cbp09, cbp10, cbp11, cbp12, cbp13, cbp14, cbp15, cbp16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Wrangle data\n",
    "\n",
    "# Variables to be used in CBP analysis, fips is combined state and county code; for others, see county_layout_2015.txt\n",
    "cbp_vars = ['fips', 'emp', 'ap', 'est', 'year']\n",
    "\n",
    "simplified_cbp_data = []\n",
    "\n",
    "for df in cbp_data:    \n",
    "    # reformat FIPS county code for merging\n",
    "    df[['fipstate', 'fipscty']] = df[['fipstate', 'fipscty']].astype(str)\n",
    "    df['fips'] = df.fipstate.str.zfill(2) + df.fipscty.str.zfill(3)\n",
    "    \n",
    "    # select aggregate county data\n",
    "    df = df[df.naics == '------']\n",
    "    \n",
    "    # drop unneccesary columns\n",
    "    df = df[cbp_vars]\n",
    "    \n",
    "    simplified_cbp_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbp_final = pd.concat(simplified_cbp_data).reset_index(drop=True)\n",
    "cbp_final = cbp_final.rename(columns={'fips': 'FIPS', 'emp': 'Employment', 'ap': 'AnnualPayroll', \n",
    "                                      'est': 'Establishments', 'year': 'Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import and Wrangle Drought Data\n",
    "\n",
    "# collect all drought file names\n",
    "drought_files = glob.glob('Data/drought/*')\n",
    "\n",
    "# import all drought tables\n",
    "drought_data = []\n",
    "for file in drought_files:\n",
    "    drought_data.append(pd.read_csv(file))\n",
    "\n",
    "simplified_drought_data = []\n",
    "\n",
    "for df in drought_data:\n",
    "    # add year column, reformat FIPS column for merging\n",
    "    df['Year'] = pd.to_datetime(df.ValidStart).dt.year\n",
    "    df['FIPS'] = df.FIPS.astype(str).str.zfill(5)\n",
    "    \n",
    "    # make sure only CA data included\n",
    "    df = df[df.FIPS.str[:2] == '06'].reset_index(drop=True)\n",
    "    \n",
    "    # average drought index per county per year\n",
    "    by_year = df.groupby(['FIPS', 'County'])[['None', 'D0', 'D1', 'D2', 'D3', 'D4']].mean().reset_index()\n",
    "    by_year['Year'] = df.Year[0]\n",
    "    \n",
    "    simplified_drought_data.append(by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drought_final = pd.concat(simplified_drought_data)\n",
    "drought_final = drought_final.rename(columns={'None': 'NoDrought'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Import and Wrangle Unemployment Data\n",
    "\n",
    "unemploy = pd.read_csv('Data/Local_Area_Unemployment_Statistics__LAUS___Annual_Average.csv')\n",
    "\n",
    "# select county unemployment data\n",
    "unemploy = unemploy[(unemploy['Area Type'] == 'County') & (unemploy['Year'] < 2017)]\n",
    "\n",
    "# select desired variable\n",
    "unemploy = unemploy[['Area Name', 'Year', 'Unemployment Rate']].reset_index(drop=True)\n",
    "\n",
    "# rename columns for merging\n",
    "unemploy = unemploy.rename(columns={'Area Name': 'County', 'Unemployment Rate': 'Unemployment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge Data Sets\n",
    "\n",
    "first_merge = pd.merge(left=cbp_final, right=drought_final, left_on=['FIPS', 'Year'], right_on=['FIPS', 'Year'], how='outer')\n",
    "project_df = pd.merge(left=first_merge, right=unemploy, left_on=['County', 'Year'], right_on=['County', 'Year'])\n",
    "project_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "income_1999 = pd.read_csv('Data/income_by_county_1999.csv', header=1)\n",
    "income_1999 = income_1999.iloc[:, 6:]\n",
    "income_1999 = income_1999.rename(columns={income_1999.columns[0]: 'County', \\\n",
    "                                          income_1999.columns[2]: '% pop. in poverty'})\n",
    "income_1999.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=income_1999.iloc[:,1], y=income_1999.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_group(poverty):\n",
    "    if poverty > 17.5:\n",
    "        return 'Low'\n",
    "    elif poverty > 10:\n",
    "        return 'Middle'\n",
    "    else:\n",
    "        return 'High'\n",
    "    \n",
    "income_1999['IncomeGroup'] = pd.Categorical(income_1999.iloc[:,2].apply(assign_group), \n",
    "                                            categories=['Low', 'Middle', 'High'], \n",
    "                                            ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_1999.iloc[:,1].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "income_1999.iloc[:,2].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_df = project_df.merge(income_1999, on='County')\n",
    "project_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Descriptive Analysis on Unemployment\n",
    "\n",
    "##Central Tendency, Variability\n",
    "project_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##size\n",
    "project_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Shape\n",
    "\n",
    "#Making a list of column variables\n",
    "col = list(project_df.columns.values)\n",
    "\n",
    "#Change shape of the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Missing Values\n",
    "\n",
    "#Checking the number of NaNs for each variable\n",
    "ur = project_df['Unemployment'].isna().sum()\n",
    "emp = project_df['Employment'].isna().sum()\n",
    "pay = project_df['AnnualPayroll'].isna().sum()\n",
    "esta = project_df['Establishments'].isna().sum()\n",
    "nd = project_df['NoDrought'].isna().sum()\n",
    "d0 = project_df['D0'].isna().sum()\n",
    "d1 = project_df['D1'].isna().sum()\n",
    "d2 = project_df['D2'].isna().sum()\n",
    "d3 = project_df['D3'].isna().sum()\n",
    "d4 = project_df['D4'].isna().sum()\n",
    "\n",
    "#Using above value to make a dictionary\n",
    "mv = {'Employment': [emp], \n",
    "      'Unemployment':[ur],\n",
    "      'Annual Payroll':[ur],\n",
    "      'Establishments':[esta],\n",
    "      'No Drought':[nd],\n",
    "      'D0':[d0],\n",
    "      'D1':[d1],\n",
    "      'D2':[d2],\n",
    "      'D3':[d3],\n",
    "      'D4':[d4]}\n",
    "\n",
    "#Making & Outputting the table for number of missing values\n",
    "mv_final = pd.DataFrame.from_dict(mv)\n",
    "mv_final.rename(index={0:'Number of Missing Values'}, inplace='True')\n",
    "mv_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Values\n",
    "\n",
    "# consider using this, it is much simpler....\n",
    "pd.DataFrame(project_df.isnull().sum()).rename(columns={0:'Number of Missing Values'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_drought(row):\n",
    "#     if row['D4'] > 0:\n",
    "#         return 5\n",
    "#     if row['D3'] > 50:\n",
    "#         return 4\n",
    "    if row['D2'] > 40:\n",
    "        return 3\n",
    "    elif row['D1'] > 50: \n",
    "        return 2\n",
    "    elif row['D0'] > 50:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "project_df['DroughtLevel'] = project_df.apply(lambda x: assign_drought(x), axis=1)\n",
    "project_df['PayPerEmployee'] = project_df['AnnualPayroll'] / project_df['Employment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = project_df.groupby(['Year', 'IncomeGroup'])[['Employment', 'AnnualPayroll', 'Establishments', 'Unemployment', \n",
    "                                                    'PayPerEmployee', 'DroughtLevel']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1,figsize=(15, 20))\n",
    "sns.pointplot(x='Year', y='PayPerEmployee', hue='IncomeGroup', size='DroughtLevel', data=dat, \n",
    "             legend='false', ax=ax1)\n",
    "ax1.legend(loc='upper left', title='Income Group')\n",
    "ax1_1 = ax1.twinx()\n",
    "sns.pointplot(x='Year', y='DroughtLevel', data=dat, \n",
    "             legend='false', ax=ax1_1, hue='IncomeGroup', markers='s', palette = sns.color_palette('YlOrRd', 3))\n",
    "ax1_1.legend(loc='lower right', title='Income Group')\n",
    "\n",
    "sns.pointplot(x='Year', y='Establishments', hue='IncomeGroup', data=dat, \n",
    "             legend='false', ax=ax2);\n",
    "ax2.legend(loc='upper left', title='Income Group')\n",
    "ax2_1 = ax2.twinx()\n",
    "sns.pointplot(x='Year', y='DroughtLevel', data=dat, palette = sns.color_palette('YlOrRd', 3), \n",
    "             legend='false', ax=ax2_1, hue='IncomeGroup', markers='s')\n",
    "ax2_1.legend(loc='center right', title='Income Group')\n",
    "\n",
    "sns.pointplot(x='Year', y='Unemployment', hue='IncomeGroup', data=dat, \n",
    "             legend='false', ax=ax3);\n",
    "ax3.legend(loc='upper left', title='Income Group')\n",
    "ax3_1 = ax3.twinx()\n",
    "sns.pointplot(x='Year', y='DroughtLevel', data=dat, \n",
    "             ax=ax3_1, hue='IncomeGroup', markers='s', palette = sns.color_palette('YlOrRd', 3))\n",
    "ax3_1.legend(loc='center right', title='Income Group')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dat = project_df.groupby('Year').mean().reset_index()\n",
    "# dat0=dat[dat.DroughtLevel==0]\n",
    "# dat1=dat[dat.DroughtLevel==1]\n",
    "# dat2=dat[dat.DroughtLevel==2]\n",
    "# dat3=dat[dat.DroughtLevel==3]\n",
    "\n",
    "# fig, axes = plt.subplots(4,3, figsize=(25, 20), sharex=True)\n",
    "\n",
    "# for row, data in zip(axes, [dat0, dat1, dat2, dat3]):\n",
    "#     ax1 = row[0]\n",
    "#     ax2 = ax1.twinx()\n",
    "#     ax1.plot(dat.Year, dat.PayPerEmployee, 'g-')\n",
    "#     ax2.plot(dat.Year, dat.DroughtLevel, 'b-')\n",
    "\n",
    "#     ax1.set_xlabel('Year')\n",
    "#     ax1.set_ylabel('Pay Per Employee', color='g')\n",
    "#     ax2.set_ylabel('Average Proportion of Counties in Severe Drought', color='b')\n",
    "    \n",
    "#     ax1 = row[1]\n",
    "#     ax2 = ax1.twinx()\n",
    "#     ax1.plot(dat.Year, dat.Unemployment, 'g-')\n",
    "#     ax2.plot(dat.Year, dat.DroughtLevel, 'b-')\n",
    "\n",
    "#     ax1.set_xlabel('Year')\n",
    "#     ax1.set_ylabel('Unemployment', color='g')\n",
    "#     ax2.set_ylabel('Average Proportion of Counties in Severe Drought', color='b')\n",
    "    \n",
    "#     ax1 = row[2]\n",
    "#     ax2 = ax1.twinx()\n",
    "#     ax1.plot(dat.Year, dat.Establishments, 'g-')\n",
    "#     ax2.plot(dat.Year, dat.DroughtLevel, 'b-')\n",
    "\n",
    "#     ax1.set_xlabel('Year')\n",
    "#     ax1.set_ylabel('Establishments', color='g')\n",
    "#     ax2.set_ylabel('Average Proportion of Counties in Severe Drought', color='b')\n",
    "\n",
    "# # ax2 = ax1.twinx()\n",
    "# # ax1.plot(dat.Year, dat.PayPerEmployee, 'g-')\n",
    "# # ax2.plot(dat.Year, dat.D2, 'b-')\n",
    "\n",
    "# # ax1.set_xlabel('Year')\n",
    "# # ax1.set_ylabel('Unemployment', color='g')\n",
    "# # ax2.set_ylabel('Proportion of No Drought', color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results = smf.ols('test ~ D2', data=after_drought[after_drought.County == 'Alameda County']).fit()\n",
    "\n",
    "# print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = project_df.drop(['NoDrought', 'D0', 'D1', 'D2', 'D3', 'D4', 'Per capita income in 1999 (dollars)', '% pop. in poverty'],axis=1)\n",
    "a = (df\n",
    " .groupby(['Year', 'DroughtLevel', 'IncomeGroup']).mean().dropna(how='all').reset_index()\n",
    " .groupby(['DroughtLevel', 'IncomeGroup'])\n",
    " .apply(lambda x: x.sort_values(by='Year').diff())#.drop(['DroughtLevel', 'IncomeGroup'],axis=1).diff())\n",
    ")\n",
    "#a = a.apply(lambda x: x / a['Year'])\n",
    "b = a.reset_index().groupby(['DroughtLevel', 'IncomeGroup'])#.Employment.plot(kind='hist')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unemployment_diff_dict = {}\n",
    "establishments_diff_dict = {}\n",
    "payperemployee_diff_dict = {}\n",
    "for name, df in b:\n",
    "    key = 'Income Group: %s, Drought Level: %s' % (name)\n",
    "    unemployment_diff_dict[key] = df.Unemployment\n",
    "    establishments_diff_dict[key] = df.Establishments\n",
    "    payperemployee_diff_dict = df.PayPerEmployee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Income Group: 0, Drought Level: High': 23         NaN\n",
       " 24    0.606410\n",
       " 25    0.316667\n",
       " 26    1.207692\n",
       " 27   -0.907692\n",
       " 28   -0.230769\n",
       " 29   -0.446154\n",
       " 30    1.694231\n",
       " 31   -0.646154\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 0, Drought Level: Low': 0          NaN\n",
       " 1     1.890000\n",
       " 2    -1.645000\n",
       " 3     0.843750\n",
       " 4    -0.961607\n",
       " 5     0.017857\n",
       " 6    -1.032895\n",
       " 7    -0.742105\n",
       " 8     2.100000\n",
       " 9     3.000000\n",
       " 10    4.094444\n",
       " 11   -0.179444\n",
       " 12   -3.148333\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 0, Drought Level: Middle': 13         NaN\n",
       " 14   -0.468333\n",
       " 15    1.558333\n",
       " 16    0.795000\n",
       " 17    0.038333\n",
       " 18   -1.295333\n",
       " 19   -0.438000\n",
       " 20    1.823214\n",
       " 21   -0.190857\n",
       " 22   -3.502000\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 1, Drought Level: High': 54         NaN\n",
       " 55    1.704545\n",
       " 56    0.022727\n",
       " 57   -0.100000\n",
       " 58    0.921875\n",
       " 59   -1.463542\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 1, Drought Level: Low': 32          NaN\n",
       " 33     0.761111\n",
       " 34     1.133333\n",
       " 35    -0.730000\n",
       " 36     2.940000\n",
       " 37    -5.950000\n",
       " 38     0.650000\n",
       " 39    10.650000\n",
       " 40    -3.950000\n",
       " 41    -1.710000\n",
       " 42    -1.595000\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 1, Drought Level: Middle': 43         NaN\n",
       " 44    0.607353\n",
       " 45   -0.082353\n",
       " 46   -0.292857\n",
       " 47   -1.153571\n",
       " 48    1.500000\n",
       " 49   -0.600000\n",
       " 50    4.775000\n",
       " 51    3.891667\n",
       " 52   -2.026190\n",
       " 53   -1.216071\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 2, Drought Level: High': 82         NaN\n",
       " 83    0.081667\n",
       " 84    1.890000\n",
       " 85    3.341429\n",
       " 86   -0.163810\n",
       " 87   -1.270000\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 2, Drought Level: Low': 60         NaN\n",
       " 61    1.783333\n",
       " 62    2.666667\n",
       " 63   -0.833333\n",
       " 64   -1.062963\n",
       " 65    4.055556\n",
       " 66    0.841667\n",
       " 67    2.225000\n",
       " 68    0.027273\n",
       " 69   -0.287879\n",
       " 70   -2.455556\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 2, Drought Level: Middle': 71         NaN\n",
       " 72    0.400000\n",
       " 73    0.650000\n",
       " 74   -0.400000\n",
       " 75    0.683333\n",
       " 76    0.133333\n",
       " 77    4.566667\n",
       " 78    1.900000\n",
       " 79   -0.320833\n",
       " 80   -5.558333\n",
       " 81    0.216667\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 3, Drought Level: High': 110         NaN\n",
       " 111    0.200000\n",
       " 112    1.300000\n",
       " 113    3.400000\n",
       " 114   -0.628846\n",
       " 115   -1.423077\n",
       " 116   -1.176923\n",
       " 117   -0.051282\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 3, Drought Level: Low': 88         NaN\n",
       " 89    7.325000\n",
       " 90   -1.100000\n",
       " 91    0.690000\n",
       " 92    4.179231\n",
       " 93    0.043590\n",
       " 94   -2.370588\n",
       " 95   -1.204412\n",
       " 96   -1.310000\n",
       " 97    0.512273\n",
       " Name: Unemployment, dtype: float64,\n",
       " 'Income Group: 3, Drought Level: Middle': 98          NaN\n",
       " 99    -1.640000\n",
       " 100    0.390000\n",
       " 101   -0.650000\n",
       " 102   -0.018182\n",
       " 103    5.304545\n",
       " 104    1.608333\n",
       " 105   -0.444444\n",
       " 106   -0.604167\n",
       " 107   -1.720833\n",
       " 108   -1.360000\n",
       " 109   -0.545263\n",
       " Name: Unemployment, dtype: float64}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemployment_diff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data for this research will only require looking at quantitative measures such as income values or disease rates, there will be no need for personal information if it presents itself. To best protect the privacy of the individuals we are collecting data from, all personal information not related to the data sets specifically (such as name or address of the household we are collecting utility data from) will be removed in the end results. We do not believe though that our question or datasets are invasive in nature and predict this will be of little occurrence if any. For our analyses, being aware of the racial inequalities present in low income communities is important. Before making any specific generalizations, we will make sure (if the data is available) that the ethnicities of households or individuals that are making up the census data are representative of the communities we are looking at. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
